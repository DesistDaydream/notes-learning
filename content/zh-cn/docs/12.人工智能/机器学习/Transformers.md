---
title: "Transformers"
linkTitle: "Transformers"
weight: 20
---

# æ¦‚è¿°

> å‚è€ƒï¼š
>
> - [GitHub é¡¹ç›®ï¼Œhuggingface/transformers](https://github.com/huggingface/transformers)
> - [Wikiï¼ŒTransformer_(machine_learning_model)](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
> - [Hugging Face åˆ›å§‹äººäº²è¿°ï¼šä¸€ä¸ª GitHub å²ä¸Šå¢é•¿æœ€å¿«çš„ AI é¡¹ç›®](https://my.oschina.net/oneflow/blog/5525728)
> - [å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/transformers/index)

**Transformer** æ˜¯ [Hugging Face](/docs/12.äººå·¥æ™ºèƒ½/Hugging%20Face.md) å¼€æºçš„æ˜¯ä¸€ç§[æ·±åº¦å­¦ä¹ ](/docs/12.äººå·¥æ™ºèƒ½/æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ .md)æ¨¡å‹ï¼Œå®ƒé‡‡ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯¹è¾“å…¥æ•°æ®çš„æ¯ä¸€éƒ¨åˆ†çš„é‡è¦æ€§è¿›è¡Œå·®å¼‚åŠ æƒã€‚å®ƒä¸»è¦ç”¨äº [è‡ªç„¶è¯­è¨€å¤„ç†(NLP)](/docs/12.äººå·¥æ™ºèƒ½/è‡ªç„¶è¯­è¨€å¤„ç†/è‡ªç„¶è¯­è¨€å¤„ç†.md) å’Œ [è®¡ç®—æœºè§†è§‰(CV)](/docs/12.äººå·¥æ™ºèƒ½/è®¡ç®—æœºè§†è§‰/è®¡ç®—æœºè§†è§‰.md) é¢†åŸŸã€‚

ğŸ¤—Â Transformers æä¾›äº†æ•°ä»¥åƒè®¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ”¯æŒ 100 å¤šç§è¯­è¨€çš„æ–‡æœ¬åˆ†ç±»ã€ä¿¡æ¯æŠ½å–ã€é—®ç­”ã€æ‘˜è¦ã€ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆã€‚å®ƒçš„å®—æ—¨æ˜¯è®©æœ€å…ˆè¿›çš„ NLP æŠ€æœ¯äººäººæ˜“ç”¨ã€‚

ğŸ¤—Â Transformers æä¾›äº†ä¾¿äºå¿«é€Ÿä¸‹è½½å’Œä½¿ç”¨çš„ APIï¼Œè®©ä½ å¯ä»¥æŠŠé¢„è®­ç»ƒæ¨¡å‹ç”¨åœ¨ç»™å®šæ–‡æœ¬ã€åœ¨ä½ çš„æ•°æ®é›†ä¸Šå¾®è°ƒç„¶åé€šè¿‡Â [model hub](https://huggingface.co/models)Â ä¸ç¤¾åŒºå…±äº«ã€‚åŒæ—¶ï¼Œæ¯ä¸ªå®šä¹‰çš„ Python æ¨¡å—å‡å®Œå…¨ç‹¬ç«‹ï¼Œæ–¹ä¾¿ä¿®æ”¹å’Œå¿«é€Ÿç ”ç©¶å®éªŒã€‚

ğŸ¤—Â Transformers æ”¯æŒä¸‰ä¸ªæœ€çƒ­é—¨çš„æ·±åº¦å­¦ä¹ åº“ï¼šÂ [Jax](https://jax.readthedocs.io/en/latest/),Â [PyTorch](https://pytorch.org/)Â ä»¥åŠÂ [TensorFlow](https://www.tensorflow.org/)Â â€” å¹¶ä¸ä¹‹æ— ç¼æ•´åˆã€‚ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨ä¸€ä¸ªæ¡†æ¶è®­ç»ƒä½ çš„æ¨¡å‹ç„¶åç”¨å¦ä¸€ä¸ªåŠ è½½å’Œæ¨ç†ã€‚

# å®‰è£… Transformers

å®‰è£… Transformers æœ¬è´¨å°±æ˜¯å®‰è£… Transformers çš„æ¨¡å‹ï¼Œå¹¶ä¸”è¿˜éœ€è¦ä¸€äº›å¯ä»¥è°ƒç”¨æ¨¡å‹çš„ä»£ç (é€šå¸¸éƒ½æ˜¯ Python åŒ…)ã€‚

Transformers æ¨¡å‹å¯ä»¥å¯¹æ¥å¤šç§çƒ­é—¨çš„æ·±åº¦å­¦ä¹ åº“ï¼š

- [PyTorch](docs/12.äººå·¥æ™ºèƒ½/æœºå™¨å­¦ä¹ /PyTorch.md)
  - æ³¨æ„ï¼šå®‰è£… PyTorch æ—¶ï¼Œå®‰è£… GPU ç‰ˆçš„ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦ä½¿ç”¨ GPU ä½†æ˜¯å´å®‰è£…çš„ CPU ç‰ˆçš„ PyTorchï¼Œå°†ä¼šæŠ¥é”™ï¼š`Torch not compiled with CUDA enabled`ã€‚è¯´ç™½äº†å°±æ˜¯ä¸‹è½½çš„ PyTorch ä¸æ˜¯åœ¨ CUDA ç¯å¢ƒä¸‹ç¼–è¯‘çš„ï¼Œæ— æ³•å¤„ç† CUDA çš„è¯·æ±‚ã€‚
- TensorFlow

åªå®‰è£… Transformers

```bash
pip install transformers
```

å®‰è£…å®Œ Transformers åŒ…åï¼Œå¯ä»¥æ ¹æ®éœ€è¦å®‰è£… PyTorchã€TensorFlow ç­‰æ·±åº¦å­¦ä¹ çš„çš„åŒ…ã€‚

# å…³è”æ–‡ä»¶ä¸é…ç½®

**~/.cache/huggingface/** # HuggingFace ç¼“å­˜è·¯å¾„ï¼Œä¿å­˜æ¨¡å‹ã€è°ƒç”¨æ¨¡å‹çš„ä»£ç  ç­‰ã€‚å¯ä»¥é€šè¿‡ `${HF_HOME}` æ›´æ”¹è·¯å¾„ä½ç½®ï¼›ä¹Ÿå¯ä»¥é€šè¿‡ `${XDG_CACHE_HOME}` æ›´æ”¹è·¯å¾„ä½ç½®ï¼Œä½†æ˜¯éœ€è¦æ³¨æ„ï¼Œ`${XDG_CACHE_HOME}` é’ˆå¯¹çš„ `~/.cache/` è¿™éƒ¨åˆ†ã€‚

- **./hub/** # é¢„è®­ç»ƒæ¨¡å‹åœ¨æœ¬åœ°ç¼“å­˜çš„ä¿å­˜è·¯å¾„ã€‚å¯ä»¥é€šè¿‡ `${HUGGINGFACE_HUB_CACHE}` ç¯å¢ƒå˜é‡å˜æ›´è·¯å¾„ä½ç½®ã€‚
- **./modules/** # 

> ä¸ºäº†é˜²æ­¢ä¸‹è½½å¾ˆå¤šæ¨¡å‹æ’‘çˆ† C ç›˜ï¼Œä¸ªäººä¹ æƒ¯è®¾ç½® `${HF_HOME}` å˜é‡ä¸º `D:\Projects\.huggingface`

# å¿«é€Ÿä½“éªŒ

åªéœ€è¦å‡ è¡Œä»£ç ï¼Œå°±å¯ä»¥åœ¨ç»™å®šä»»åŠ¡ä¸­ä¸‹è½½å’Œä½¿ç”¨ä»»ä½•é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™é‡Œå®˜æ–¹ä½¿ç”¨äº†ä¸€ä¸ªæƒ…ç»ªåˆ†ææ¨¡å‹ï¼Œç”¨ä»¥åˆ†ææŒ‡å®šæ–‡æœ¬çš„æƒ…ç»ªæ˜¯æ­£å‘çš„è¿˜æ˜¯è´Ÿå‘çš„ï¼š

```python
>>> from transformers import pipeline

# ä¸‹è½½å¹¶ç¼“å­˜ pipline ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹
>>> classifier = pipeline('sentiment-analysis')
# è¯„ä¼°ç»™å®šçš„æ–‡æœ¬
>>> classifier('We are very happy to introduce pipeline to the transformers repository.')
[{'label': 'POSITIVE', 'score': 0.9996980428695679}]
```

transformers åº“ä¼šè‡ªåŠ¨ä» Hugging Face ä¸­ä¸‹è½½åä¸º sentiment-analysis åˆ°é»˜è®¤çš„ç¼“å­˜è·¯å¾„ä¸­ã€‚

## é«˜çº§ä½“éªŒ

æœ‰æ—¶æˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹å¯èƒ½ä¼šäº§ç”ŸæŸäº›é—®é¢˜ï¼Œæ­¤æ—¶æˆ‘ä»¬å¯ä»¥æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ï¼Œæ¯”å¦‚æˆ‘ä»¬ç”¨æ¸…åå¼€æºçš„ chatglm-6b æ¨¡å‹ä¸¾ä¾‹ï¼Œåªéœ€è¦å…ˆåœ¨æœ¬åœ°ç›®å½•ä¸‹è½½æ¨¡å‹ `git clone https://huggingface.co/THUDM/chatglm-6b-int`ï¼Œç„¶åè¿è¡Œå¦‚ä¸‹ä»£ç å³å¯ä½¿ç”¨ CPU ä½“éªŒã€‚å…¶ä¸­æ³¨æ„è¦å®‰è£… chatglm-6b é¡¹ç›®ä¸­çš„ Python ä¾èµ–ã€‚

```python
from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained("D:\Projects\DesistDaydream\python-transformers\chatglm-6b-int4", trust_remote_code=True)
model = AutoModel.from_pretrained("D:\Projects\DesistDaydream\python-transformers\chatglm-6b-int4",trust_remote_code=True).float()
model = model.eval()
response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
print(response)
```

ä»£ç è¿è¡Œåï¼Œè·å¾—å›å¤ï¼š

```bash
~]# python demo.py
ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
```

